{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import metrics\n",
    "import numpy as np\n",
    "\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import urllib.request\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(root, test_ratio=0.2, max_items_per_class=10000):\n",
    "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
    "\n",
    "    # initialize variables\n",
    "    x = np.empty([0, 784])\n",
    "    y = np.empty([0])\n",
    "    class_names = []\n",
    "\n",
    "    # load each data file\n",
    "    for idx, file in enumerate(all_files):\n",
    "        class_name = file.split('.')[0]\n",
    "        class_names.append(class_name)\n",
    "\n",
    "        data = np.load(file)\n",
    "        # print('class[%s] has %d samples' % (class_name, data.shape[0]))\n",
    "        data = data[0: max_items_per_class, :]\n",
    "        labels = np.full(data.shape[0], idx)\n",
    "\n",
    "        x = np.append(x, data, axis=0)\n",
    "        y = np.append(y, labels)\n",
    "\n",
    "    data = None\n",
    "    labels = None\n",
    "\n",
    "    # randomize the dataset\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    x = x[permutation, :]\n",
    "    y = y[permutation]\n",
    "\n",
    "    # separate into training and testing\n",
    "    test_size = int(x.shape[0]/100*(test_ratio*100))\n",
    "\n",
    "    x_test = x[0:test_size, :]\n",
    "    y_test = y[0:test_size]\n",
    "\n",
    "    x_train = x[test_size:, :]\n",
    "    y_train = y[test_size:]\n",
    "    return x_train, y_train, x_test, y_test, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test, class_names = load_data('data', max_items_per_class=100)\n",
    "num_classes = len(class_names)\n",
    "image_size = 28\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (169600, 784)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape: ', x_train.shape)\n",
    "assert x_train.shape[0] == y_train.shape[0]\n",
    "assert x_test.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\tooth\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Show some random data\"\"\"\n",
    "idx = randint(0, len(x_train))\n",
    "rand_x = x_train[idx].reshape(28, 28)\n",
    "plt.imshow(rand_x)\n",
    "print(class_names[int(y_train[idx].item())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"# Preprocess the Data\"\"\"\n",
    "\n",
    "# Reshape and normalize\n",
    "x_train = x_train.reshape(\n",
    "    x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
    "x_test = x_test.reshape(\n",
    "    x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
    "\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "# Convert class vectors to class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 53)                6837      \n",
      "=================================================================\n",
      "Total params: 103,989\n",
      "Trainable params: 103,989\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Convolution2D(16, (3, 3),\n",
    "                               padding='same',\n",
    "                               input_shape=(image_size, image_size, 1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compile model\n",
    "adam = tf.train.AdamOptimizer()\n",
    "\n",
    "# top-N\n",
    "TOP_N = 5\n",
    "\n",
    "def top_n_categorical_accuracy(y_pred, y_label):\n",
    "    return metrics.top_k_categorical_accuracy(y_pred, y_label, k=TOP_N)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy', top_n_categorical_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 152640 samples, validate on 16960 samples\n",
      "Epoch 1/10\n",
      "152640/152640 [==============================] - 184s 1ms/step - loss: 1.5598 - acc: 0.5929 - top_n_categorical_accuracy: 0.8361 - val_loss: 1.0897 - val_acc: 0.7186 - val_top_n_categorical_accuracy: 0.9070\n",
      "Epoch 2/10\n",
      "152640/152640 [==============================] - 188s 1ms/step - loss: 0.9591 - acc: 0.7484 - top_n_categorical_accuracy: 0.9231 - val_loss: 0.8953 - val_acc: 0.7692 - val_top_n_categorical_accuracy: 0.9285\n",
      "Epoch 3/10\n",
      "152640/152640 [==============================] - 189s 1ms/step - loss: 0.8127 - acc: 0.7852 - top_n_categorical_accuracy: 0.9373 - val_loss: 0.8513 - val_acc: 0.7774 - val_top_n_categorical_accuracy: 0.9325\n",
      "Epoch 4/10\n",
      "152640/152640 [==============================] - 199s 1ms/step - loss: 0.7293 - acc: 0.8053 - top_n_categorical_accuracy: 0.9450 - val_loss: 0.7718 - val_acc: 0.8003 - val_top_n_categorical_accuracy: 0.9407\n",
      "Epoch 5/10\n",
      "152640/152640 [==============================] - 179s 1ms/step - loss: 0.6739 - acc: 0.8195 - top_n_categorical_accuracy: 0.9503 - val_loss: 0.7499 - val_acc: 0.8029 - val_top_n_categorical_accuracy: 0.9425\n",
      "Epoch 6/10\n",
      "152640/152640 [==============================] - 171s 1ms/step - loss: 0.6299 - acc: 0.8308 - top_n_categorical_accuracy: 0.9544 - val_loss: 0.7488 - val_acc: 0.8055 - val_top_n_categorical_accuracy: 0.9423\n",
      "Epoch 7/10\n",
      "152640/152640 [==============================] - 171s 1ms/step - loss: 0.5936 - acc: 0.8399 - top_n_categorical_accuracy: 0.9579 - val_loss: 0.7175 - val_acc: 0.8157 - val_top_n_categorical_accuracy: 0.9443\n",
      "Epoch 8/10\n",
      "152640/152640 [==============================] - 178s 1ms/step - loss: 0.5640 - acc: 0.8465 - top_n_categorical_accuracy: 0.9606 - val_loss: 0.7087 - val_acc: 0.8154 - val_top_n_categorical_accuracy: 0.9463\n",
      "Epoch 9/10\n",
      "152640/152640 [==============================] - 179s 1ms/step - loss: 0.5373 - acc: 0.8532 - top_n_categorical_accuracy: 0.9629 - val_loss: 0.7062 - val_acc: 0.8203 - val_top_n_categorical_accuracy: 0.9463\n",
      "Epoch 10/10\n",
      "152640/152640 [==============================] - 175s 1ms/step - loss: 0.5143 - acc: 0.8594 - top_n_categorical_accuracy: 0.9650 - val_loss: 0.6998 - val_acc: 0.8195 - val_top_n_categorical_accuracy: 0.9476\n",
      "cost time 30m12s\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "\"\"\"# Training\"\"\"\n",
    "\n",
    "history = model.fit(x=x_train, y=y_train, validation_split=0.1, batch_size=128, verbose=1, epochs=10)\n",
    "\n",
    "cost_time = time.time() - starttime\n",
    "print('cost time {:.0f}m{:.0f}s'.format(cost_time/60, cost_time%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.698, Test accurracy: 81.93%, top-5 accuarcy: 94.60%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('loss: {:.3f}, Test accurracy: {:.2f}%, top-{} accuarcy: {:0.2f}%'\n",
    "      .format(score[0], score[1] * 100, TOP_N, score[2] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Inference\"\"\"\n",
    "\n",
    "model.save('quickDraw.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "idx = randint(0, len(x_test))\n",
    "print(idx, x_test.shape, y_test.shape)\n",
    "pred = model.predict(np.expand_dims(x_test[idx], axis=0))\n",
    "print(pred.shape)\n",
    "\n",
    "pred1 = pred[0].argmax()\n",
    "print(pred1)\n",
    "print(int(y_test[idx].argmax().item()))\n",
    "#pred2 = (-pred[0]).argsort()[:5]\n",
    "#print(pred2)\n",
    "\n",
    "plt.imshow(x_test[idx].squeeze()) \n",
    "print(\"%s %2.f%% %s\" % (class_names[int(pred1.item())],pred[0][pred1]*100 , class_names[int(y_test[idx].argmax().item())]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
